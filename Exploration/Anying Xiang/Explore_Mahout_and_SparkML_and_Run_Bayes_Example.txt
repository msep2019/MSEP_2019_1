Explore Mahout and SparkML and Run Bayes Example on Hadoop and Spark

Running on Hadoop with Mahout
1. Mahout is related with MapReduce and Hadoop, using distributed computing in Machine Learning.

2. The official example of Hadoop is "https://mahout.apache.org/users/classification/twenty-newsgroups.html".

3. Mahout CBayes is used in this example.

4. "pom.xml" is needed when "mvn -DskipTests clean install" or "mvn clean install  -DskipTests  -Dmaven.javadoc.skip=true" to compile mahout.
    Errors met here: 
    1) Error: Could not find or load main class org.apache.mahout.driver.MahoutDriver
    2) If using the release version, there is no need to compile mahout...

5. Errors while running Naive Bayes:
    1) Exception in thread "main" java.lang.IllegalArgumentException: Can not create a Path from an empty string
    solve -> check the path String

6. I created a Maven project in Eclipse, and then the "pom.xml" of this particular project is under the root of the project.

7. Be careful that there is no "mahout-core-0.xx.jar" in the version 0.13.0.

8. The steps have caused some errors, so I changed them a little bit to run successfully.
    The main steps are as follows:
    1) Process data set and change into the format of <Text, Text> SequenceFile.
    2) Use HDFS or local. 
    (If HDFS, remember to start HDFS before, or "failed on connection exception".)
    3) Train the model with train data, and save the model.
    4) Test with test data.

9. Last parts of the output:
19/04/02 10:51:50 INFO LocalJobRunner: map
19/04/02 10:51:50 INFO Task: Task 'attempt_local1071429109_0001_m_000000_0' done.
19/04/02 10:51:50 INFO LocalJobRunner: Finishing task: attempt_local1071429109_0001_m_000000_0
19/04/02 10:51:50 INFO LocalJobRunner: map task executor complete.
19/04/02 10:51:51 INFO Job:  map 100% reduce 0%
19/04/02 10:51:51 INFO Job: Job job_local1071429109_0001 completed successfully
19/04/02 10:51:51 INFO Job: Counters: 18
    File System Counters
        FILE: Number of bytes read=96680303
        FILE: Number of bytes written=86575239
        FILE: Number of read operations=0
        FILE: Number of large read operations=0
        FILE: Number of write operations=0
    Map-Reduce Framework
        Map input records=7558
        Map output records=7558
        Input split bytes=123
        Spilled Records=0
        Failed Shuffles=0
        Merged Map outputs=0
        GC time elapsed (ms)=19
        CPU time spent (ms)=0
        Physical memory (bytes) snapshot=0
        Virtual memory (bytes) snapshot=0
        Total committed heap usage (bytes)=127729664
    File Input Format Counters 
        Bytes Read=8685571
    File Output Format Counters 
        Bytes Written=1435671
19/04/02 10:51:51 INFO TestNaiveBayesDriver: Complementary Results: 
=======================================================
Summary
-------------------------------------------------------
Correctly Classified Instances          :       6763       89.4813%
Incorrectly Classified Instances        :        795       10.5187%
Total Classified Instances              :       7558

=======================================================
Confusion Matrix
-------------------------------------------------------
a       b       c       d       e       f       g       h       i       j       k       l       m       n       o       p       q       r       s       t       <--Classified as
299     0       0       0       0       0       0       0       0       0       0       0       0       0       6       3       0       0       0       5        |  313     a     = alt.atheism
0       322     3       12      8       15      9       2       2       2       3       4       7       1       10      2       3       0       2       1        |  408     b     = comp.graphics
6       20      249     47      7       8       9       5       2       2       4       5       6       3       2       2       2       2       6       4        |  391     c     = comp.os.ms-windows.misc
0       4       7       319     12      6       12      3       4       2       3       3       7       3       2       1       2       0       0       1        |  391     d     = comp.sys.ibm.pc.hardware
0       2       1       8       375     4       8       1       2       3       3       2       6       0       2       2       0       0       1       0        |  420     e     = comp.sys.mac.hardware
1       8       2       6       3       375     3       1       2       2       0       3       2       2       4       0       1       0       2       1        |  418     f     = comp.windows.x
1       3       3       21      12      3       258     17      6       5       3       2       10      2       5       2       3       2       4       2        |  364     g     = misc.forsale
0       2       0       0       3       0       1       361     6       3       2       1       2       1       1       0       4       1       2       0        |  390     h     = rec.autos
2       0       0       0       0       1       1       2       414     1       0       0       0       0       0       0       1       0       0       0        |  422     i     = rec.motorcycles
0       0       0       0       1       0       1       1       1       386     7       0       1       1       1       1       0       0       0       0        |  401     j     = rec.sport.baseball
1       0       0       1       0       0       1       0       0       0       380     0       0       0       0       0       1       0       1       0        |  385     k     = rec.sport.hockey
0       0       1       0       0       3       0       0       0       0       0       377     0       0       1       0       2       1       0       0        |  385     l     = sci.crypt
2       3       3       17      3       2       6       2       3       2       1       1       323     4       4       2       0       0       2       1        |  381     m     = sci.electronics
2       0       0       1       0       0       1       2       0       0       0       1       3       378     1       1       0       0       2       2        |  394     n     = sci.med
0       1       0       1       0       0       0       2       0       1       0       0       1       0       360     0       3       1       1       0        |  371     o     = sci.space
4       0       0       2       1       0       2       0       0       1       1       0       0       4       0       380     1       3       0       6        |  405     p     = soc.religion.christian
0       0       0       1       0       1       0       1       0       0       0       1       0       0       1       0       352     2       4       0        |  363     q     = talk.politics.guns
1       0       0       0       0       0       0       0       0       2       0       0       0       0       0       1       0       399     1       0        |  404     r     = talk.politics.mideast
1       0       1       0       1       2       0       1       0       1       1       4       0       4       1       0       3       4       283     3        |  310     s     = talk.politics.misc
36      0       0       0       0       1       0       0       0       0       0       1       0       0       2       23      3       0       3       173      |  242     t     = talk.religion.misc

=======================================================
Statistics
-------------------------------------------------------
Kappa                                       0.8609
Accuracy                                   89.4813%
Reliability                                84.9159%
Reliability (standard deviation)            0.2201
Weighted precision                          0.8952
Weighted recall                             0.8948
Weighted F1 score                           0.8925

19/04/02 10:51:51 INFO MahoutDriver: Program took 10579 ms (Minutes: 0.17631666666666668)


Spark with Mahout
1. The official explanation of Spark Naive Bayes is "http://mahout.apache.org/users/algorithms/spark-naive-bayes.html".
About how to run on Spark: "https://mahout.apache.org/users/sparkbindings/play-with-shell.html".

2. "cnaivebayes-Spark" is the Spark version.


Spark with SparkML
1. The official doc: "https://spark.apache.org/docs/1.2.2/ml-guide.html".
    About Naive Bayes: "https://spark.apache.org/docs/1.2.2/api/scala/index.html#org.apache.spark.mllib.classification.NaiveBayesModel".
    Naive Bayes Example: "https://spark.apache.org/docs/2.2.0/mllib-naive-bayes.html".

2. The logic of scala object:
    1) SparkConf & SparkContext.
    2) Train "NaiveBayes" with training data.
    3) model.predict & Calculate accuracy.
    4) Save model.

3. Last parts of the output:
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 269
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 279
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 278
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 281
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 272
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 280
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 285
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 276
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 287
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 277
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 267
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 274
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 275
2019-04-02 12:25:57 INFO  ContextCleaner:54 - Cleaned accumulator 268
2019-04-02 12:25:57 INFO  CodeGenerator:54 - Code generated in 238.363534 ms
2019-04-02 12:25:57 INFO  CodeGenerator:54 - Code generated in 105.14025 ms
2019-04-02 12:25:57 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 155.0 KB, free 977.2 MB)
2019-04-02 12:25:57 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 13.3 KB, free 977.2 MB)
2019-04-02 12:25:57 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on jzd:39863 (size: 13.3 KB, free: 977.6 MB)
2019-04-02 12:25:57 INFO  SparkContext:54 - Created broadcast 13 from take at NaiveBayes.scala:216
2019-04-02 12:25:57 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
2019-04-02 12:25:57 INFO  SparkContext:54 - Starting job: take at NaiveBayes.scala:216
2019-04-02 12:25:57 INFO  DAGScheduler:54 - Got job 9 (take at NaiveBayes.scala:216) with 1 output partitions
2019-04-02 12:25:57 INFO  DAGScheduler:54 - Final stage: ResultStage 11 (take at NaiveBayes.scala:216)
2019-04-02 12:25:57 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-04-02 12:25:57 INFO  DAGScheduler:54 - Missing parents: List()
2019-04-02 12:25:57 INFO  DAGScheduler:54 - Submitting ResultStage 11 (MapPartitionsRDD[40] at take at NaiveBayes.scala:216), which has no missing parents
2019-04-02 12:25:57 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 12.5 KB, free 977.1 MB)
2019-04-02 12:25:57 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.2 KB, free 977.1 MB)
2019-04-02 12:25:57 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on jzd:39863 (size: 5.2 KB, free: 977.6 MB)
2019-04-02 12:25:57 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1161
2019-04-02 12:25:57 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[40] at take at NaiveBayes.scala:216) (first 15 tasks are for partitions Vector(0))
2019-04-02 12:25:57 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 1 tasks
2019-04-02 12:25:57 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 16, localhost, executor driver, partition 0, PROCESS_LOCAL, 8430 bytes)
2019-04-02 12:25:57 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 16)
2019-04-02 12:25:57 INFO  FileScanRDD:54 - Reading File path: file:///home/jzd/eclipse-spark-workspace/WordCount/target/tmp/myNaiveBayesModel/data/part-00000-ffb9b111-e151-41f0-9b9f-af1a00837f15-c000.snappy.parquet, range: 0-4076, partition values: [empty row]
2019-04-02 12:25:58 INFO  ParquetReadSupport:54 - Going to read the following fields from the Parquet file:

Parquet form:
message spark_schema {
  optional group labels (LIST) {
    repeated group list {
      required double element;
    }
  }
  optional group pi (LIST) {
    repeated group list {
      required double element;
    }
  }
  optional group theta (LIST) {
    repeated group list {
      optional group element (LIST) {
        repeated group list {
          required double element;
        }
      }
    }
  }
  optional binary modelType (UTF8);
}

Catalyst form:
StructType(StructField(labels,ArrayType(DoubleType,true),true), StructField(pi,ArrayType(DoubleType,true),true), StructField(theta,ArrayType(ArrayType(DoubleType,true),true),true), StructField(modelType,StringType,true))
       
2019-04-02 12:25:58 INFO  CodeGenerator:54 - Code generated in 63.792028 ms
2019-04-02 12:25:58 INFO  InternalParquetRecordReader:211 - RecordReader initialized will read a total of 1 records.
2019-04-02 12:25:58 INFO  InternalParquetRecordReader:125 - at row 0. reading next block
2019-04-02 12:25:58 INFO  CodecPool:184 - Got brand-new decompressor [.snappy]
2019-04-02 12:25:58 INFO  InternalParquetRecordReader:134 - block read in memory in 52 ms. row count = 1
2019-04-02 12:25:58 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 16). 3682 bytes result sent to driver
2019-04-02 12:25:58 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 16) in 767 ms on localhost (executor driver) (1/1)
2019-04-02 12:25:58 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2019-04-02 12:25:58 INFO  DAGScheduler:54 - ResultStage 11 (take at NaiveBayes.scala:216) finished in 0.867 s
2019-04-02 12:25:58 INFO  DAGScheduler:54 - Job 9 finished: take at NaiveBayes.scala:216, took 0.881772 s
2019-04-02 12:25:58 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-04-02 12:25:58 INFO  AbstractConnector:318 - Stopped Spark@4cca6857{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2019-04-02 12:25:58 INFO  SparkUI:54 - Stopped Spark web UI at http://jzd:4041
2019-04-02 12:25:58 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-04-02 12:25:58 INFO  MemoryStore:54 - MemoryStore cleared
2019-04-02 12:25:58 INFO  BlockManager:54 - BlockManager stopped
2019-04-02 12:25:58 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-04-02 12:25:58 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-04-02 12:25:58 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-04-02 12:25:58 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-04-02 12:25:58 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-a41c584d-75fb-4b8e-a62b-ee3371a63c46
