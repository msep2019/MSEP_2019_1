
Balancer is a tool to balance the workload across datanodes (over-utilized and under-utilized).  
When running the large data volume, the data in HDFS storage can become skewed, like some datanodes may have more data blocks while others are less.
When the 'skewed' cases occur, the data blocks are extrmely not balance compared with other datanodes, the read and write activity will become over busy for one node and other nodes are underutilized.

balancer can be ran by this command:
$HADOOP_HOME/sbin/start-balancer.sh

I tried to run this command but and get outcome:
ulimit -a for user hadoop
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 7594
max locked memory       (kbytes, -l) 16384
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 7594
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

but did not observe the response time get much improve

reference:
http://www.informit.com/articles/article.aspx?p=2755708&seqNum=5
https://www.cloudera.com/documentation/enterprise/5-7-x/topics/admin_hdfs_balancer.html

